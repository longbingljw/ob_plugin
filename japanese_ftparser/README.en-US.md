# OceanBase Japanese Fulltext Parser Plugin

A Japanese fulltext parser plugin for OceanBase. It uses JNI bridge to call Java tokenization libraries (integrated with Apache Lucene JapaneseAnalyzer/Kuromoji).

## Features

- âœ… Compatible with OceanBase FTParser interface (`japanese_ftparser_main.cpp`)
- âœ… JNI integration for Java Japanese tokenization (Lucene JapaneseAnalyzer/Kuromoji)
- âœ… UTF-8 multi-byte Japanese text processing
- âœ… Extensible: Java tokenization implementation can be replaced

## Build

### Environment Setup

1. Install basic build tools
```bash
yum install -y git cmake make glibc-devel glibc-headers gcc gcc-c++
```
This command installs the gcc development environment.

> Skip this step if your environment already has these tools

2. Install OceanBase Plugin Development Kit
```bash
yum install -y oceanbase-plugin-dev-kit
```

### Compilation

```bash
# Choose your workspace directory
cd `your/workspace`
# Download source code
git clone https://github.com/oceanbase/oceanbase-plugins
# Build
cd oceanbase-plugins/japanese_ftparser
mkdir build
cd build
cmake ..
make
```
You will see the libjapanese_ftparser.so file in the build directory. This is the dynamic library plugin.

## Quick Start

### Deployment and Installation

**Recommended method**: Copy .class files and jar files to corresponding locations separately

```bash
# 1. Copy plugin dynamic library
cp /path/to/yourplugindirpath/libjapanese_ftparser.so /path/to/observer/plugin_dir/

# 2. Create java directory structure (if not exists)
mkdir -p /path/to/observer/java/lib

# 3. Copy Lucene dependency libraries
cp java/lib/lucene-core-8.11.2.jar /path/to/observer/java/lib/
cp java/lib/lucene-analyzers-common-8.11.2.jar /path/to/observer/java/lib/
cp java/lib/lucene-analyzers-kuromoji-8.11.2.jar /path/to/observer/java/lib/

# 4. Copy Japanese segmenter class file
cp java/JapaneseSegmenter.class /path/to/observer/java/

# 5. Install Java environment
yum install java-1.8.0-openjdk-devel -y

# 6. Start Observer and load plugin
# Connect to database
obclient -h127.0.0.1 -P2881 -uroot@sys -pdifyai123456 # Example with dify database connection info

# Set plugin loading in sys tenant
ALTER SYSTEM SET plugins_load='libjapanese_ftparser.so:on';

# Restart Observer to take effect
killall observer
cd /path/to/observer
./bin/observer  # Start observer in the observer working directory

# Verify installation (see below)
```

**Multi-plugin Coexistence Notes**:
- If other language parser plugins are already installed, only copy Japanese-specific jar files and .class files
- `lucene-core-8.11.2.jar` and `lucene-analyzers-common-8.11.2.jar` are shared by all plugins
- `lucene-analyzers-kuromoji-8.11.2.jar` is only needed by the Japanese parser
- When files already exist, cp command will ask for overwrite confirmation, you can choose to skip


> ğŸ“– **Detailed Plugin Usage**: Refer to [OceanBase Plugin Development Kit User Manual](https://oceanbase.github.io/oceanbase-plugin-dev-kit/user-guide/)

### Dependency Search Priority

The plugin automatically searches for Java dependencies in the following priority order:

1. **Environment Variable** (Highest Priority)
   ```bash
   export OCEANBASE_PARSER_CLASSPATH="/custom/path/lucene-core-8.11.2.jar:/custom/path/lucene-analyzers-common-8.11.2.jar:/custom/path/lucene-analyzers-kuromoji-8.11.2.jar:/custom/path"
   ```

2. **Observer Working Directory** (Recommended)
   ```
   ${OB_WORKDIR}/java/lib/lucene-core-8.11.2.jar
   ${OB_WORKDIR}/java/lib/lucene-analyzers-common-8.11.2.jar  
   ${OB_WORKDIR}/java/lib/lucene-analyzers-kuromoji-8.11.2.jar
   ${OB_WORKDIR}/java/JapaneseSegmenter.class
   ```

3. **Plugin Relative Path** (Development Environment)
   ```
   ./java/lib/lucene-*.jar
   ```

**Recommendation**: Use method 2 (copy java directory), no need to configure OCEANBASE_PARSER_CLASSPATH for quick experience

### Installation Verification

```sql
-- Check if plugin is loaded successfully
SELECT * FROM oceanbase.GV$OB_PLUGINS WHERE NAME = 'japanese_ftparser';

-- Create test table (ensure shell character encoding is UTF-8)
CREATE TABLE t_japanese (
    c1 INT, 
    c2 VARCHAR(200), 
    c3 TEXT, 
    FULLTEXT INDEX (c2, c3) WITH PARSER japanese_ftparser
);

-- Insert Japanese test data
INSERT INTO t_japanese (c1, c2, c3) VALUES
(1, 'ã“ã‚“ã«ã¡ã¯', 'ã“ã‚“ã«ã¡ã¯ã€ç§ãŸã¡ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã¸ã‚ˆã†ã“ã'),
(2, 'ã‚ã‚ŠãŒã¨ã†', 'ã”è¨ªå•ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™'),
(3, 'ãŠå•ã„åˆã‚ã›', 'ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€å–¶æ¥­æ—¥ã«ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„'),
(4, 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™', 'ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã”åˆ©ç”¨ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™'),
(5, 'ã‚ˆã†ã“ã', 'OceanBaseã¸ã‚ˆã†ã“ã'),
(6, 'ã“ã‚“ã«ã¡ã¯', 'ã“ã‚“ã«ã¡ã¯ã€ã¾ãŸãŠä¼šã„ã§ãã‚‹ã“ã¨ã‚’æ¥½ã—ã¿ã«ã—ã¦ã„ã¾ã™'),
(7, 'ã„ã‹ãŒã§ã™ã‹', 'æœ€è¿‘ã„ã‹ãŒãŠéã”ã—ã§ã—ã‚‡ã†ã‹'),
(8, 'å•é¡Œã‚ã‚Šã¾ã›ã‚“', 'ä½•ã‚‚å•é¡Œã‚ã‚Šã¾ã›ã‚“'),
(9, 'ãƒ•ã‚©ãƒ¼ãƒ å…¥åŠ›', 'æƒ…å ±ã‚’å®Œå…¨ã«å…¥åŠ›ã—ã¦ãã ã•ã„'),
(10, 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸ', 'ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€ã¾ãŸå°†æ¥ãŠä¼šã„ã§ãã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™'),
(11, 'ã“ã‚“ã«ã¡ã¯', 'ã“ã‚“ã«ã¡ã¯ã€ã“ã‚“ã«ã¡ã¯'),
(12, 'ç¹°ã‚Šè¿”ã—ãƒ†ã‚¹ãƒˆ', 'ãƒ‘ãƒ¼ã‚µãƒ¼ãŒé‡è¤‡ã™ã‚‹å˜èªã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆã—ã¾ã™'),
(13, 'ä½•ã§ã‚‚ã„ã„', 'ã‚ãªãŸãŒå¿…è¦ã¨ã™ã‚‹ã‚‚ã®ã¯ä½•ã§ã‚‚'),
(14, 'èª°ã‚‚ç†è§£ã—ãªã„', 'ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹èª°ã‚‚ç†è§£ã—ã¦ã„ã¾ã›ã‚“'),
(15, 'é€šå¸¸é€šã‚Š', 'ã™ã¹ã¦é€šå¸¸é€šã‚Šã§ã™'),
(16, '2025å¹´ã¯è‰¯ã„å¹´', '2025å¹´ã¯é–‹ç™ºã«ã¨ã£ã¦è‰¯ã„å¹´ã§ã™'),
(17, '2025å¹´ã‚ã‚ŠãŒã¨ã†', '2025å¹´ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™'),
(18, 'OceanBaseãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹', 'OceanBaseãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’é¸ã¶ç†ç”±');

-- Test fulltext search functionality
SELECT TOKENIZE('ã”è³ªå•ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€å–¶æ¥­æ—¥ã«ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„','japanese_ftparser', '[{"output": "all"}]');

-- Test 1: Single word matching (expected to return c1 = 3)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('æ°—è»½' IN NATURAL LANGUAGE MODE);

-- Test 2: Multiple word matching (expected to return c1 = 1, 5, 6, 11)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('ã“ã‚“ã«ã¡ã¯ ã‚ˆã†ã“ã' IN NATURAL LANGUAGE MODE);

-- Test 3: Stopword test (should return no results if "ã®" is a stopword)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('ã®' IN NATURAL LANGUAGE MODE);

-- Test 4: Number + Japanese mixed (expected to return c1 = 16, 17)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('2025' IN NATURAL LANGUAGE MODE);

-- Test 5: Repeated words (expected to return c1 = 12)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('ãƒ†ã‚¹ãƒˆ' IN NATURAL LANGUAGE MODE);

-- Test 6: Fuzzy matching (expected to return c1 = 2, 4, 10, 17)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('ã‚ã‚ŠãŒã¨ã†' IN NATURAL LANGUAGE MODE);

-- Test 7: Verify key Japanese sentence search (expected to return c1 = 18)
SELECT * FROM t_japanese
WHERE MATCH(c2, c3) AGAINST('ç†ç”±' IN NATURAL LANGUAGE MODE);
```

## Technical Specifications

### ES Complete Solution

The Japanese tokenizer adopts the Elasticsearch complete solution:

```
Configuration: CustomAnalyzer.builder()
  .withTokenizer("japanese")                    // kuromoji_tokenizer
  .addTokenFilter("japaneseBaseForm")           // kuromoji_baseform  
  .addTokenFilter("japanesePartOfSpeechStop")   // kuromoji_part_of_speech
  .addTokenFilter("cjkWidth")                   // cjk_width
  .addTokenFilter("lowercase")                  // lowercase
  .addTokenFilter("stop")                       // ja_stop

Features:
- BaseForm stemming: Unifies verb/adjective inflections to their base forms
- Stopword removal: Removes functional words like particles and pronouns
- Character width normalization: Unifies full-width and half-width characters
- Lowercase conversion: Unifies alphabet cases
```

### Alignment with Dify Configuration

This plugin is fully aligned with Dify's Elasticsearch Japanese configuration:

```json
{
  "analysis": {
    "analyzer": {
      "ja_analyzer": {
        "type": "custom",
        "tokenizer": "kuromoji_tokenizer",
        "filter": [
          "kuromoji_baseform",      // âœ… Implemented
          "kuromoji_part_of_speech", // âœ… Implemented  
          "ja_stop",                // âœ… Implemented
          "kuromoji_number",        // Future enhancement
          "kuromoji_stemmer"        // Future enhancement
        ]
      }
    }
  }
}
```

**A Japanese tokenization solution optimized for database fulltext search**.
